{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i058959/miniconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from mxnet import nd\n",
    "from mxnet.gluon import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.1 Inheried from Block\n",
    "page 114"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Block):\n",
    "    \"\"\"\n",
    "    declared layer with model parameters, here we use 2 full connected layers\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Call MLP's parent class and initialization\n",
    "        \"\"\"\n",
    "        # Issue: 4.1.5.1, if don't call super(), then, self._children doesn't exists\n",
    "        # -Cause issue-> AttributeError: 'MLP' object has no attribute '_children'\n",
    "        super(MLP, self).__init__(**kwargs)\n",
    "        # hidden layer\n",
    "        self.hidden = nn.Dense(256, activation='relu')\n",
    "        # output layer\n",
    "        self.output = nn.Dense(10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        define model's forward calcuation\n",
    "        \"\"\"\n",
    "        return self.output(self.hidden(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.09543003  0.04614332 -0.00286653 -0.07790346 -0.05130243  0.02942039\n",
       "   0.08696645 -0.0190793  -0.04122177  0.05088576]\n",
       " [ 0.0769287   0.03099705  0.00856576 -0.04467198 -0.0692684   0.09132432\n",
       "   0.06786594 -0.06187843 -0.03436674  0.04234695]]\n",
       "<NDArray 2x10 @cpu(0)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = nd.random.uniform(shape=(2, 20))\n",
    "net = MLP()\n",
    "net.initialize()\n",
    "net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.2 Sequential inheried from Block\n",
    "page 115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySequential(nn.Block):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MySequential, self).__init__(**kwargs)\n",
    "        \n",
    "    def add(self, block: nn.Block):\n",
    "        \"\"\"\n",
    "        block is a nn.Block instance, supposed that it has a unique name, We stored it into Block's instance variables,\n",
    "        whose type is OrderedDick. And when call initialize() function, system will automatially initialize for _children.\n",
    "        \"\"\"\n",
    "        self._children[block.name] = block\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        OrderedDict guarantee that using pre-defined elements for processing\n",
    "        \"\"\"\n",
    "        for block in self._children.values():\n",
    "            x = block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.0036223   0.00633331  0.03201144 -0.01369375  0.10336448 -0.03508019\n",
       "  -0.00032164 -0.01676024  0.06978628  0.01303308]\n",
       " [ 0.03871716  0.02608212  0.03544959 -0.02521311  0.11005434 -0.01430662\n",
       "  -0.03052465 -0.03852826  0.06321152  0.0038594 ]]\n",
       "<NDArray 2x10 @cpu(0)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MySequential()\n",
    "net.add(nn.Dense(256, activation='relu'))\n",
    "net.add(nn.Dense(10))\n",
    "net.initialize()\n",
    "net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.3 Complex model without learning parameters\n",
    "page 116"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = nd.random.uniform(shape=(2, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FancyMLP(nn.Block):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(FancyMLP, self).__init__(**kwargs)\n",
    "        # using get_constant() create random weights, which don't change during training\n",
    "        self.rand_weight = self.params.get_constant('rand_weight', nd.random.uniform(shape=(20, 20)))\n",
    "        self.dense = nn.Dense(20, activation='relu')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.dense(x)\n",
    "        # using created constant parameter, and NDArray's relu and dot function => Don't learn self.rand_weight\n",
    "        x = nd.relu(nd.dot(x, self.rand_weight.data()) + 1)\n",
    "        # reuse full connected layer\n",
    "        x = self.dense(x)\n",
    "        ## result: [26.93217]\n",
    "        ## control flow, using asscalar to return scalar comparsion\n",
    "        # refer to http://mathworld.wolfram.com/L2-Norm.html of definition of L2 norm\n",
    "#         print(\"x:\", x)\n",
    "#         print(\"x.norm():\", x.norm())\n",
    "        while x.norm().asscalar() > 1:\n",
    "            x /= 2\n",
    "        if x.norm().asscalar() < 0.8:\n",
    "            x *= 10\n",
    "## result : [33.071712]\n",
    "#         while x.norm() > 1:\n",
    "#             x /= 2\n",
    "#         if x.norm() < 0.8:\n",
    "#             x *= 10\n",
    "        return x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[3.536038]\n",
       "<NDArray 1 @cpu(0)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = FancyMLP()\n",
    "net.initialize()\n",
    "# 1. must conform to column size, to 30 will cause \"MXNetError: Shape inconsistent, Provided = [20,30], inferred shape=(20,20)\"\n",
    "# x = nd.random.uniform(shape=(3, 30))\n",
    "# 2. row could be changed\n",
    "net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NestMLP(nn.Block):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(NestMLP, self).__init__(**kwargs)\n",
    "        self.net = nn.Sequential()\n",
    "        self.net.add(nn.Dense(64, activation='relu'),\n",
    "                    nn.Dense(32, activation='relu'))\n",
    "#         # issue: TypeError: 'list' object is not callable\n",
    "#         self.net = [nn.Dense(64, activation='relu'),\n",
    "#                      nn.Dense(32, activation='relu')]\n",
    "        self.dense = nn.Dense(16, activation='relu')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.dense(self.net(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[4.310071]\n",
       "<NDArray 1 @cpu(0)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential()\n",
    "net.add(NestMLP(), nn.Dense(20), FancyMLP())\n",
    "net.initialize()\n",
    "net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Model parameters\n",
    "page 118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import init, nd\n",
    "from mxnet.gluon import nn\n",
    "\n",
    "net = nn.Sequential()\n",
    "net.add(nn.Dense(256, activation='relu'))\n",
    "net.add(nn.Dense(10))\n",
    "net.initialize()\n",
    "\n",
    "x = nd.random.uniform(shape=(2, 20))\n",
    "y = net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 Access model parameters\n",
    "page 118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dense10_ (\n",
       "  Parameter dense10_weight (shape=(256, 20), dtype=float32)\n",
       "  Parameter dense10_bias (shape=(256,), dtype=float32)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter dense10_weight (shape=(256, 20), dtype=float32),\n",
       " Parameter dense10_weight (shape=(256, 20), dtype=float32))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the default weight name and access data\n",
    "net[0].params['dense10_weight'], net[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[-0.03555115  0.01875034  0.02322027 ...  0.06564643  0.04601197\n",
       "  -0.01915742]\n",
       " [ 0.05949537 -0.01434531 -0.06355897 ... -0.05305162  0.06888158\n",
       "  -0.0361836 ]\n",
       " [-0.03508119 -0.03804309 -0.05517314 ... -0.0514059  -0.01693203\n",
       "  -0.01760576]\n",
       " ...\n",
       " [ 0.03173313  0.01789995  0.02519771 ... -0.06176154 -0.03986754\n",
       "  -0.04898471]\n",
       " [ 0.00564718  0.04665586 -0.00028374 ...  0.05332779  0.02100175\n",
       "  -0.06427249]\n",
       " [ 0.0438781   0.05357236  0.02753124 ...  0.04084889 -0.01963295\n",
       "   0.05668835]]\n",
       "<NDArray 256x20 @cpu(0)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0. 0. 0. ... 0. 0. 0.]\n",
       " [0. 0. 0. ... 0. 0. 0.]\n",
       " [0. 0. 0. ... 0. 0. 0.]\n",
       " ...\n",
       " [0. 0. 0. ... 0. 0. 0.]\n",
       " [0. 0. 0. ... 0. 0. 0.]\n",
       " [0. 0. 0. ... 0. 0. 0.]]\n",
       "<NDArray 256x20 @cpu(0)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as no backpropagate, with grad all zeros\n",
    "net[0].weight.grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
       "<NDArray 10 @cpu(0)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[1].bias.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sequential2_ (\n",
       "  Parameter dense10_weight (shape=(256, 20), dtype=float32)\n",
       "  Parameter dense10_bias (shape=(256,), dtype=float32)\n",
       "  Parameter dense11_weight (shape=(10, 256), dtype=float32)\n",
       "  Parameter dense11_bias (shape=(10,), dtype=float32)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find all net parameters\n",
    "net.collect_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sequential2_ (\n",
       "  Parameter dense10_weight (shape=(256, 20), dtype=float32)\n",
       "  Parameter dense11_weight (shape=(10, 256), dtype=float32)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find all regex weights parameters\n",
    "net.collect_params('.*weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 Access model parameters\n",
    "page 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[-0.00045153 -0.0007181  -0.00303942  0.00052552 -0.00951675 -0.00264655\n",
       "  0.00024275  0.01360035 -0.01203111  0.00198488 -0.01178844 -0.00134574\n",
       " -0.0096758  -0.02177683  0.01439619  0.01977801  0.00150742  0.00320251\n",
       " -0.01048041 -0.01397015]\n",
       "<NDArray 20 @cpu(0)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 非首次对模型初始化需要指定 force_reinit, initialization as nomralization\n",
    "net.initialize(init=init.Normal(sigma=0.01), force_reinit=True) \n",
    "net[0].weight.data()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
       "<NDArray 20 @cpu(0)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize as constant\n",
    "net.initialize(init=init.Constant(1), force_reinit=True)\n",
    "net[0].weight.data()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[ 0.02390976 -0.03466652 -0.07621067 -0.11896712 -0.09759908  0.14299902\n",
       "  0.10603461  0.11694542 -0.13018094 -0.06749497 -0.00866343 -0.00790583\n",
       " -0.11328436 -0.00597025 -0.01266268  0.00247419  0.14153317  0.13778725\n",
       " -0.02249777 -0.1179658 ]\n",
       "<NDArray 20 @cpu(0)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize via init.Xavier\n",
    "net.initialize(init=init.Xavier(), force_reinit=True)\n",
    "net[0].weight.data()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3 Customized initialization method\n",
    "page 121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyInit(init.Initializer):\n",
    "    def _init_weight(self, name, data):\n",
    "        print('Init', name, data.shape)\n",
    "        data[:] = nd.random.uniform(low=-10, high=10, shape=data.shape)\n",
    "        data *= data.abs() >= 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init dense10_weight (256, 20)\n",
      "Init dense11_weight (10, 256)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "[-6.008077   0.        -0.        -0.         0.        -0.\n",
       " -0.        -8.591784   5.629592  -0.         5.0204325 -0.\n",
       "  8.544237  -6.7921295 -9.420949  -0.         7.913826  -8.087603\n",
       " -0.         7.4220505]\n",
       "<NDArray 20 @cpu(0)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.initialize(MyInit(), force_reinit=True)\n",
    "net[0].weight.data()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[-5.008077   1.         1.         1.         1.         1.\n",
       "  1.        -7.5917835  6.629592   1.         6.0204325  1.\n",
       "  9.544237  -5.7921295 -8.420949   1.         8.913826  -7.0876026\n",
       "  1.         8.42205  ]\n",
       "<NDArray 20 @cpu(0)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for set_data() to overwerite model parameter\n",
    "net[0].weight.set_data(net[0].weight.data() + 1)\n",
    "net[0].weight.data()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.4 Shared model parameters\n",
    "page 122"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[-2.8930701e-05 -9.8856308e-06 -2.9208031e-05  2.2878423e-05\n",
       "  -2.3972660e-05  3.5956542e-05 -2.5916641e-05  7.8715402e-08\n",
       "  -2.5550988e-05 -1.0085280e-05]\n",
       " [ 3.8551381e-05  2.4488436e-06 -3.2839023e-05  5.3968040e-05\n",
       "  -2.9661947e-05 -2.2196458e-05 -5.3009750e-05  6.9562004e-05\n",
       "  -5.2102761e-05 -5.6052133e-05]]\n",
       "<NDArray 2x10 @cpu(0)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential()\n",
    "shared = nn.Dense(8, activation='relu')\n",
    "net.add(\n",
    "    nn.Dense(8, activation='relu'),\n",
    "    shared,\n",
    "    # shared parameter for layer 2 and 3\n",
    "    nn.Dense(8, activation='relu', params=shared.params),\n",
    "    nn.Dense(10)\n",
    ")\n",
    "net.initialize()\n",
    "\n",
    "x = nd.random.uniform(shape=(2, 20))\n",
    "net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Model Lazy Initialization\n",
    "\n",
    "### 4.3.1 Lazy initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import init, nd\n",
    "from mxnet.gluon import nn\n",
    "\n",
    "class MyInit(init.Initializer):\n",
    "    def _init_weight(self, name, data):\n",
    "        print(\"Init\", name, data.shape)\n",
    "        # avoid initialization logic here\n",
    "        \n",
    "net = nn.Sequential()\n",
    "net.add(\n",
    "    nn.Dense(256, activation='relu'),\n",
    "    nn.Dense(10)\n",
    ")\n",
    "net.initialize(init=MyInit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init dense16_weight (256, 20)\n",
      "Init dense17_weight (10, 256)\n"
     ]
    }
   ],
   "source": [
    "# during initalization, there is no _init_weight prompt\n",
    "# using shape reasoning and intialize weights\n",
    "x = nd.random.uniform(shape=(2, 20))\n",
    "y = net(x)\n",
    "# Side effect: we can't get model parameter, before the first time of forward propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2 Avoid lazy initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init dense16_weight (256, 20)\n",
      "Init dense17_weight (10, 256)\n"
     ]
    }
   ],
   "source": [
    "# 当系统在调用 initialize函数时能够知道所有参数形状，那么延后初始化就不会发生。\n",
    "# 我们这里给两个这样的情况。\n",
    "# 第一个是模型已经被初始化过，而且我们要对模型进行重新初始化时。因为我们知道参数大小不会变，所以能够立即进行重新初始化。\n",
    "net.initialize(init=MyInit(), force_reinit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init dense18_weight (256, 20)\n",
      "Init dense19_weight (10, 256)\n"
     ]
    }
   ],
   "source": [
    "#  第二种情况是我们在创建层到时候指定了每个层的输入大小，使得系统不需要额外的信息来推测 参数形状。\n",
    "net = nn.Sequential()\n",
    "net.add(nn.Dense(256, in_units=20, activation='relu'))\n",
    "net.add(nn.Dense(10, in_units=256))\n",
    "net.initialize(init=MyInit())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Customized Layer\n",
    "\n",
    "### 4.4.1 Customized layer without model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import nd, gluon\n",
    "from mxnet.gluon import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CenteredLayer(nn.Block):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(CenteredLayer, self).__init__(**kwargs)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x - x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[-2. -1.  0.  1.  2.]\n",
       "<NDArray 5 @cpu(0)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = CenteredLayer()\n",
    "layer(nd.arange(1, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.9645086e-10"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# more complex model\n",
    "net = nn.Sequential()\n",
    "net.add(\n",
    "    nn.Dense(128),\n",
    "    CenteredLayer()\n",
    ")\n",
    "net.initialize()\n",
    "y = net(nd.random.uniform(shape=(4, 8)))\n",
    "y.mean().asscalar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.2 Customized layer with model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       "  Parameter param2 (shape=(2, 3), dtype=<class 'numpy.float32'>)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = gluon.ParameterDict()\n",
    "params.get('param2', shape=(2, 3))\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(nn.Block):\n",
    "    \"\"\"\n",
    "    units: output nubmer of layer\n",
    "    in_units: input number \n",
    "    \"\"\"\n",
    "    def __init__(self, units, in_units, **kwargs):\n",
    "        super(MyDense, self).__init__(**kwargs)\n",
    "        self.weight = self.params.get('weight', shape=(in_units, units))\n",
    "        self.bias = self.params.get('bias', shape=(units, ))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        linear = nd.dot(x, self.weight.data()) + self.bias.data() \n",
    "        return nd.relu(linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mydense0_ (\n",
       "  Parameter mydense0_weight (shape=(10, 5), dtype=<class 'numpy.float32'>)\n",
       "  Parameter mydense0_bias (shape=(5,), dtype=<class 'numpy.float32'>)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense = MyDense(units=5, in_units=10)\n",
    "dense.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0.07590036 0.19890553 0.06891428 0.         0.        ]\n",
       " [0.09435701 0.13325097 0.03792883 0.         0.        ]]\n",
       "<NDArray 2x5 @cpu(0)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense.initialize()\n",
    "dense(nd.random.uniform(shape=(2, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0.00054134 0.        ]\n",
       " [0.         0.        ]]\n",
       "<NDArray 2x2 @cpu(0)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential()\n",
    "net.add(\n",
    "    MyDense(32, in_units=64),\n",
    "    MyDense(2, in_units=32)\n",
    ")\n",
    "net.initialize()\n",
    "net(nd.random.uniform(shape=(2, 64)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Read and Store\n",
    "\n",
    "### 4.5.1 Read Write NDArrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import nd\n",
    "from mxnet.gluon import nn \n",
    "x = nd.ones(3)\n",
    "nd.save('x', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       " [1. 1. 1.]\n",
       " <NDArray 3 @cpu(0)>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = nd.load('x')\n",
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       " [1. 1. 1.]\n",
       " <NDArray 3 @cpu(0)>, \n",
       " [0. 0. 0. 0.]\n",
       " <NDArray 4 @cpu(0)>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = nd.zeros(4)\n",
    "nd.save('xy', [x, y])\n",
    "x2, y2 = nd.load('xy')\n",
    "(x2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': \n",
       " [1. 1. 1.]\n",
       " <NDArray 3 @cpu(0)>, 'y': \n",
       " [0. 0. 0. 0.]\n",
       " <NDArray 4 @cpu(0)>}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict = {'x':x, 'y':y}\n",
    "nd.save('mydict', mydict)\n",
    "mydict2 = nd.load('mydict')\n",
    "mydict2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.2 Read Write Parameters of Gluon Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Block):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MLP, self).__init__(**kwargs)\n",
    "        self.hidden = nn.Dense(256, activation='relu')\n",
    "        self.output = nn.Dense(10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.output(self.hidden(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MLP()\n",
    "net.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 由于延后初始化，我们需要先运行一次前向计算才能实际初始化模型参数。 \n",
    "x = nd.random.uniform(shape=(2, 20))\n",
    "y = net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'mlp.params'\n",
    "net.save_parameters(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = MLP()\n",
    "net2.load_parameters(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[1.]\n",
       "<NDArray 1 @cpu(0)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2 = net2(x)\n",
    "np.all(y2 == y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 GPU device\n",
    "### 4.6.1 NDarray GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(cpu(0), gpu(0), gpu(1))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mxnet as mx \n",
    "from mxnet import nd\n",
    "from mxnet.gluon import nn \n",
    "\n",
    "mx.cpu(), mx.gpu(), mx.gpu(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cpu(0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = nd.array([1, 2, 3])\n",
    "x.context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[1. 2. 3.]\n",
       "<NDArray 3 @gpu(0)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = nd.array([1, 2, 3], ctx=mx.gpu())\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0.59119    0.313164   0.76352036]\n",
       " [0.9731786  0.35454726 0.11677533]]\n",
       "<NDArray 2x3 @gpu(1)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = nd.random.uniform(shape=(2, 3), ctx=mx.gpu(1))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[1. 2. 3.]\n",
       "<NDArray 3 @gpu(0)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.copyto(mx.gpu())\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[1. 2. 3.]\n",
       "<NDArray 3 @gpu(0)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x.as_in_context(mx.gpu())\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.as_in_context(mx.gpu()) is y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.copyto(mx.gpu()) is y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[ 20.085537 109.1963   445.2395  ]\n",
       "<NDArray 3 @gpu(0)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPU calcuation\n",
    "# 注意，MXNet 要求计算的所有输入数据都在同一个 CPU/GPU 上。这个设计的原因是不同 CPU/GPU 之间的数据交互通常比较耗时。\n",
    "# 因此，MXNet 希望用戶确切地指明计算的输入数据都在同一个 CPU/GPU 上。例如，如果将 CPU 上的 x 和 GPU 上的 y 做运算，会出现错误信息。\n",
    "(z + 2).exp() * y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6.2 Gluon GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential()\n",
    "net.add(nn.Dense(1))\n",
    "net.initialize(ctx=mx.gpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[-0.03091596]\n",
       " [-0.06183191]\n",
       " [-0.09274787]]\n",
       "<NDArray 3x1 @gpu(0)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 当输入是 GPU 上的 NDArray 时，Gluon 会在相同的 GPU 上计算结果。\n",
    "net(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[-0.03091596]]\n",
       "<NDArray 1x1 @gpu(0)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
